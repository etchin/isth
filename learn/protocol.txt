==========================================================================================

SIMPLE/TRIVIAL/TOP PREDICTOR

1. Make top-var file containing the 5-top correlated variables with outcome (CNS_Sev,
ARF, ENCPHPTHY, HPTN, DIAL)

2. Test simple predictor that outputs non-recovery if any of these variables is yes/0:

python toppred.py ../mirador top-vars

==========================================================================================

LAB-RESULTS PREDICTOR

1. Set age to 10-60, deselect all columns except Lab results, day 1, sort at p-value = 0.001, export data

2. Split between train and test

python split.py lab lab/train/ lab/test

3. Impute missing data in train set

library(Amelia)
data <- read.table('lab/train/data.tsv', sep = "\t", header=TRUE, na.strings="\\N")
imputed <- amelia(data, m = 5)
missmap(imputed) # optional
write.amelia(obj=imputed, file.stem="lab/train/imputed-data", format="csv", row.names=FALSE)

4. Normalize data of first imputed dataset to make categories to be either 0 or 1.

python normalize.py lab/train/imputed-data1.csv lab/train/train-data.csv OUTCOME

5. Run logistic predictor and get parameters for lab-results predictor:

python logpred.py lab/train/train-data.csv lab-results-params -reg 0.08 -bfgs

6. Run script to test the performance of the hi-lo predictor on the test set:

python labpred.py lab/test lab-results-params

==========================================================================================

HI-LO PREDICTOR

STEP 0: CONSTRUCT TRAINING AND TEST SETS

1. Generate train and testing sets from original data:

python split.py ../mirador train test

train will contain data.tsv with 70% of data, and test 30%

STEP 1: CONSTRUCT PREDICTOR FOR HIGH-RISK GROUP

1. Open train data in Mirador, remove Treatment and ... columns, and sort OUTCOME at P-value 
of 0.001, export data for top 5 variables.

2. Impute missing data in R using Amelia (http://gking.harvard.edu/amelia/):

library(Amelia)
data <- read.table('high-risk/profile-data.tsv', sep = "\t", header=TRUE, na.strings="\\N")
nominal = c("OUTCOME", "CNS_Sev", "ARF", "ENCPHPTHY", "HPTN", "DIAL")
imputed <- amelia(data, m = 5, noms = nominal)
missmap(imputed) # optional
write.amelia(obj=imputed, file.stem="high-risk/imputed-data", format="csv", row.names=FALSE)

3. Normalize data of first imputed dataset to make categories to be either 0 or 1.

python normalize.py high-risk/imputed-data1.csv high-risk/train-data.csv OUTCOME CNS_Sev ARF ENCPHPTHY HPTN DIAL

4. Run logistic predictor and get parameters for high-risk composite in next step:

python logpred.py high-risk/train-data.csv high-risk-params -reg 0.08 -bfgs

5. Add High-Risk composite variable to training dataset:

python composite.py train hrisk.py

------------------------------------------------------------------------------------------
STEP 2: CONSTRUCT PREDICTOR FOR LOW-RISK GROUP

1. Open augmented training dataset and use the High-Risk composite as covariate to restrict
patients to those with a score lower than 0.5. Fix outliers, set P-value, sort and select 
only lab result variables. Export resulting data to low-risk

2. Impute missing data in R using Amelia

library(Amelia)
data <- read.table('low-risk/profile-data.tsv', sep = "\t", header=TRUE, na.strings="\\N")
imputed <- amelia(data, m = 5)
missmap(imputed) # optional
write.amelia(obj=imputed, file.stem="low-risk/imputed-data", format="csv", row.names=FALSE)

3. Normalize data of first imputed dataset to make categories to be either 0 or 1.

python normalize.py low-risk/imputed-data1.csv low-risk/train-data.csv OUTCOME

4. Run logistic predictor and get parameters for low-risk predictor:

python logpred.py low-risk/train-data.csv low-risk-params -reg 0.08 -bfgs

------------------------------------------------------------------------------------------

STEP 3: EVALUATE HI-LO PREDICTOR

1. Run script to test the performance of the hi-lo predictor on the test set:

python hilopred.py test high-risk-params low-risk-params

